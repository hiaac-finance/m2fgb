{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from fairgbm import FairGBMClassifier\n",
    "\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "import data\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(\n",
    "        trial,\n",
    "        scorer,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        A_train,\n",
    "        X_val,\n",
    "        Y_val,\n",
    "        A_val,\n",
    "        model_class,\n",
    "        param_space,\n",
    "        random_state = None\n",
    "):  \n",
    "    params = {}\n",
    "    for name, values in param_space.items():\n",
    "        if values[\"type\"] == \"int\":\n",
    "            values_cp = {n: v for n, v in values.items() if n != \"type\"}\n",
    "            params[name] = trial.suggest_int(name, **values_cp)\n",
    "        elif values[\"type\"] == \"categorical\":\n",
    "            values_cp = {n: v for n, v in values.items() if n != \"type\"}\n",
    "            params[name] = trial.suggest_categorical(name, **values_cp)\n",
    "        elif values[\"type\"] == \"float\":  # corrected this line\n",
    "            values_cp = {n: v for n, v in values.items() if n != \"type\"}\n",
    "            params[name] = trial.suggest_float(name, **values_cp)\n",
    "\n",
    "    model = model_class(**params)\n",
    "    if isinstance(model, FairGBMClassifier):\n",
    "        model.fit(X_train, Y_train, constraint_group=A_train)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train, A_train)\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    return scorer(Y_val, Y_val_pred, A_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgroup_feature(dataset, X_train, X_val, X_test):\n",
    "    if dataset == \"german2\":\n",
    "        A_train = X_train.Gender.astype(str) + \"_\" + (X_train.Age > 50).astype(str)\n",
    "        A_val = X_val.Gender.astype(str) + \"_\" + (X_val.Age > 50).astype(str)\n",
    "        A_test = X_test.Gender.astype(str) + \"_\" + (X_test.Age > 50).astype(str)\n",
    "    elif dataset == \"adult\":\n",
    "        A_train = X_train.sex.astype(str) + \"_\" + (X_train.age > 50).astype(str)\n",
    "        A_val = X_val.sex.astype(str) + \"_\" + (X_val.age > 50).astype(str)\n",
    "        A_test = X_test.sex.astype(str) + \"_\" + (X_test.age > 50).astype(str)\n",
    "\n",
    "    sensitive_map = dict([\n",
    "        (attr, i)\n",
    "        for i, attr in enumerate(A_train.unique())\n",
    "    ])\n",
    "    A_train = A_train.map(sensitive_map)\n",
    "    A_val = A_val.map(sensitive_map)\n",
    "    A_test = A_test.map(sensitive_map)\n",
    "    return A_train, A_val, A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(y_ground, y_prob, y_pred, A):\n",
    "    acc = accuracy_score(y_ground, y_pred)\n",
    "    roc = roc_auc_score(y_ground, y_prob)\n",
    "    eq_loss = utils.equalized_loss_score(y_ground, y_prob, A)\n",
    "    eod = utils.equal_opportunity_score(y_ground, y_pred, A)\n",
    "    spd = utils.statistical_parity_score(y_ground, y_pred, A)\n",
    "    return {\n",
    "        \"acc\" : acc,\n",
    "        \"roc\" : roc,\n",
    "        \"eq_loss\" : eq_loss,\n",
    "        \"eod\" : eod,\n",
    "        \"spd\" : spd\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, random_state=None):\n",
    "    if model_name == \"XtremeFair\":\n",
    "        def model(**params):\n",
    "            return models.XtremeFair(random_state= random_state, **params)\n",
    "    elif model_name == \"XtremeFair_grad\":\n",
    "        def model(**params):\n",
    "            return models.XtremeFair(dual_learning=\"gradient\", random_state= random_state, **params)\n",
    "    elif model_name == \"XGBClassifier\":\n",
    "        def model(**params):\n",
    "            assert params[\"fair_weight\"] == 0\n",
    "            return models.XtremeFair(random_state= random_state, **params)\n",
    "    elif model_name == \"FairGBMClassifier\":\n",
    "        def model(**params):\n",
    "            return FairGBMClassifier(random_state= random_state, **params)\n",
    "    return model\n",
    "    \n",
    "def get_param_spaces(model_name):\n",
    "    if model_name == \"XtremeFair\":\n",
    "        return models.PARAM_SPACES[\"XtremeFair\"]\n",
    "    elif model_name == \"XtremeFair_grad\":\n",
    "        return models.PARAM_SPACES[\"XtremeFair\"]\n",
    "    elif model_name == \"XGBClassifier\":\n",
    "        return models.PARAM_SPACES[\"XGBClassifier\"]\n",
    "    elif model_name == \"FairGBMClassifier\":\n",
    "        return models.PARAM_SPACES[\"FairGBMClassifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_experiment(args):\n",
    "    # create output directory if not exists\n",
    "    if not os.path.exists(args[\"output_dir\"]):\n",
    "        os.makedirs(args[\"output_dir\"])\n",
    "\n",
    "    # clear best_params.txt if exists\n",
    "    if os.path.exists(os.path.join(args[\"output_dir\"], f\"best_params.txt\")):\n",
    "        os.remove(os.path.join(args[\"output_dir\"], f\"best_params.txt\"))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    cat_features = data.CAT_FEATURES[args[\"dataset\"]]\n",
    "    num_features = data.NUM_FEATURES[args[\"dataset\"]]\n",
    "    col_trans = ColumnTransformer(\n",
    "        [\n",
    "            (\"numeric\", StandardScaler(), num_features),\n",
    "            (\n",
    "                \"categorical\",\n",
    "                OneHotEncoder(\n",
    "                    drop=\"if_binary\", sparse_output=False, handle_unknown=\"ignore\"\n",
    "                ),\n",
    "                cat_features,\n",
    "            ),\n",
    "        ],\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "    col_trans.set_output(transform=\"pandas\")\n",
    "    scorer = utils.get_combined_metrics_scorer(\n",
    "        alpha=args[\"alpha\"], performance_metric=\"acc\", fairness_metric=\"eod\"\n",
    "    )\n",
    "\n",
    "    for i in tqdm(range(10)):\n",
    "        # Load and prepare data\n",
    "        X_train, Y_train, X_val, Y_val, X_test, Y_test = data.get_fold(\n",
    "            args[\"dataset\"], i, 0\n",
    "        )\n",
    "\n",
    "        # Define sensitive attribute from gender and age\n",
    "        A_train, A_val, A_test = get_subgroup_feature(\n",
    "            args[\"dataset\"], X_train, X_val, X_test\n",
    "        )\n",
    "\n",
    "        preprocess = Pipeline([(\"preprocess\", col_trans)])\n",
    "        preprocess.fit(X_train)\n",
    "        X_train = preprocess.transform(X_train)\n",
    "        X_val = preprocess.transform(X_val)\n",
    "        X_test = preprocess.transform(X_test)\n",
    "\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        objective = lambda trial: run_trial(\n",
    "            trial,\n",
    "            scorer,\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            A_train,\n",
    "            X_val,\n",
    "            Y_val,\n",
    "            A_val,\n",
    "            get_model(args[\"model_name\"]),\n",
    "            get_param_spaces(args[\"model_name\"]),\n",
    "            0,\n",
    "        )\n",
    "        study.optimize(objective, n_trials=args[\"n_trials\"])\n",
    "\n",
    "        # save best params\n",
    "        with open(os.path.join(args[\"output_dir\"], f\"best_params.txt\"), \"a+\") as f:\n",
    "            f.write(str(study.best_params))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        model = get_model(args[\"model_name\"])(**study.best_params)\n",
    "        if isinstance(model, FairGBMClassifier):\n",
    "            model.fit(X_train, Y_train, constraint_group=A_train)\n",
    "        else:\n",
    "            model.fit(X_train, Y_train, A_train)\n",
    "        y_prob = model.predict_proba(X_train)[:, 1]\n",
    "        thresh = utils.get_best_threshold(Y_train, y_prob)\n",
    "        y_prob_test = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred_test = y_prob_test > thresh\n",
    "\n",
    "        metrics = eval_model(Y_test, y_prob_test, y_pred_test, A_test)\n",
    "        results.append(metrics)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv(os.path.join(args[\"output_dir\"], \"results.csv\"))\n",
    "    results.mean().to_csv(os.path.join(args[\"output_dir\"], \"results_mean.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset_name):\n",
    "    experiments = glob.glob(f\"../results/subgroup_experiment/{dataset_name}/*\")\n",
    "    results = []\n",
    "    for experiment in experiments:\n",
    "        df = pd.read_csv(os.path.join(experiment, \"results.csv\"))\n",
    "        df[\"experiment\"] = experiment.split(\"/\")[-1]\n",
    "        df[\"eq_loss\"] = 1 - df[\"eq_loss\"].abs()\n",
    "        df[\"spd\"] = 1 - df[\"spd\"].abs()\n",
    "        df[\"eod\"] = 1 - df[\"eod\"].abs()\n",
    "        results.append(df.iloc[:, 1:])\n",
    "    results = pd.concat(results)\n",
    "    # for each experiment, calculate the mean and std of each metric\n",
    "    results_mean = results.groupby(\"experiment\").mean()\n",
    "    results_std = results.groupby(\"experiment\").std()\n",
    "    \n",
    "    # combine dataframes into one with reorganized columns\n",
    "    results = pd.concat([results_mean, results_std], axis=1)\n",
    "    results.columns = pd.MultiIndex.from_product([[\"mean\", \"std\"], results_mean.columns])\n",
    "    results = results.swaplevel(axis=1)\n",
    "    results = results[[\"roc\", \"acc\", \"eod\",\"eq_loss\", \"spd\"]]\n",
    "    results = results.round(3)\n",
    "    print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [06:47<03:15, 65.28s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10/10 [09:11<00:00, 55.13s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 1,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german2/XtremeFair_1\",\n",
    "    \"model_name\" : \"XtremeFair\",\n",
    "    \"n_trials\" : 100\n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 1,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german2/XtremeFair_grad\",\n",
    "    \"model_name\" : \"XtremeFair_grad\",\n",
    "    \"n_trials\" : 100\n",
    "    \n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/utils.py:126: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(y_ground * np.log(y_prob) + (1 - y_ground) * np.log(1 - y_prob))\n",
      " 70%|███████   | 7/10 [03:36<01:11, 23.98s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10/10 [05:02<00:00, 30.22s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 1,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german2/XGBClassifier\",\n",
    "    \"model_name\" : \"XGBClassifier\",\n",
    "    \"n_trials\" : 100\n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:38<00:16,  5.50s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10/10 [00:52<00:00,  5.25s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 1,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german2/FairGBMClassifier\",\n",
    "    \"model_name\" : \"FairGBMClassifier\",\n",
    "    \"n_trials\" : 100\n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:45<01:42, 14.70s/it]/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:70: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:91: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:70: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:91: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      " 70%|███████   | 7/10 [01:51<00:47, 15.87s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 90%|█████████ | 9/10 [02:24<00:16, 16.61s/it]/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:70: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/models.py:91: RuntimeWarning: overflow encountered in exp\n",
      "  predt = 1 / (1 + np.exp(-predt))\n",
      "100%|██████████| 10/10 [02:43<00:00, 16.31s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 0.75,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german2/XtremeFair_1_alpha_075\",\n",
    "    \"model_name\" : \"XtremeFair\",\n",
    "    \"n_trials\" : 100\n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:14<00:58, 19.49s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10/10 [03:02<00:00, 18.28s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 0.75,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german2/XtremeFair_grad_alpha_075\",\n",
    "    \"model_name\" : \"XtremeFair_grad\",\n",
    "    \"n_trials\" : 100\n",
    "    \n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             roc           acc           eod        eq_loss  \\\n",
      "                            mean    std   mean    std   mean    std    mean   \n",
      "experiment                                                                    \n",
      "FairGBMClassifier          0.751  0.049  0.696  0.041  0.613  0.224   0.581   \n",
      "XGBClassifier              0.778  0.050  0.718  0.053  0.715  0.096   0.575   \n",
      "XtremeFair_1               0.779  0.043  0.706  0.058  0.636  0.254   0.513   \n",
      "XtremeFair_1_alpha_075     0.764  0.042  0.687  0.061  0.643  0.188   0.227   \n",
      "XtremeFair_grad            0.783  0.050  0.711  0.066  0.694  0.153   0.547   \n",
      "XtremeFair_grad_alpha_075  0.780  0.052  0.709  0.075  0.661  0.262   0.384   \n",
      "\n",
      "                                    spd         \n",
      "                             std   mean    std  \n",
      "experiment                                      \n",
      "FairGBMClassifier          0.352  0.518  0.219  \n",
      "XGBClassifier              0.198  0.644  0.098  \n",
      "XtremeFair_1               0.313  0.664  0.131  \n",
      "XtremeFair_1_alpha_075     0.279  0.662  0.154  \n",
      "XtremeFair_grad            0.286  0.566  0.177  \n",
      "XtremeFair_grad_alpha_075  0.388  0.642  0.177  \n"
     ]
    }
   ],
   "source": [
    "summarize(\"german2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dual_fair_boost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

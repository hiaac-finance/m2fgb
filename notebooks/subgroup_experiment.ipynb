{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "import data\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(\n",
    "        trial,\n",
    "        scorer,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        A_train,\n",
    "        X_val,\n",
    "        Y_val,\n",
    "        A_val,\n",
    "        model_class,\n",
    "        param_space,\n",
    "        random_state = None\n",
    "):  \n",
    "    params = {}\n",
    "    for name, values in param_space.items():\n",
    "        if values[\"type\"] == \"int\":\n",
    "            values_cp = {n: v for n, v in values.items() if n != \"type\"}\n",
    "            params[name] = trial.suggest_int(name, **values_cp)\n",
    "        elif values[\"type\"] == \"categorical\":\n",
    "            values_cp = {n: v for n, v in values.items() if n != \"type\"}\n",
    "            params[name] = trial.suggest_categorical(name, **values_cp)\n",
    "        elif values[\"type\"] == \"float\":  # corrected this line\n",
    "            values_cp = {n: v for n, v in values.items() if n != \"type\"}\n",
    "            params[name] = trial.suggest_float(name, **values_cp)\n",
    "\n",
    "    params[\"seed\"] = random_state\n",
    "    model = model_class(**params)\n",
    "    model.fit(X_train, Y_train, A_train)\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    return scorer(Y_val, Y_val_pred, A_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgroup_feature(dataset, X_train, X_val, X_test):\n",
    "    if dataset == \"german2\":\n",
    "        A_train = X_train.Gender.astype(str) + \"_\" + (X_train.Age > 50).astype(str)\n",
    "        A_val = X_val.Gender.astype(str) + \"_\" + (X_val.Age > 50).astype(str)\n",
    "        A_test = X_test.Gender.astype(str) + \"_\" + (X_test.Age > 50).astype(str)\n",
    "\n",
    "    sensitive_map = dict([\n",
    "        (attr, i)\n",
    "        for i, attr in enumerate(A_train.unique())\n",
    "    ])\n",
    "    A_train = A_train.map(sensitive_map)\n",
    "    A_val = A_val.map(sensitive_map)\n",
    "    A_test = A_test.map(sensitive_map)\n",
    "    return A_train, A_val, A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(y_ground, y_prob, y_pred, A):\n",
    "    acc = accuracy_score(y_ground, y_pred)\n",
    "    roc = roc_auc_score(y_ground, y_prob)\n",
    "    eq_loss = utils.equalized_loss_score(y_ground, y_prob, A)\n",
    "    eod = utils.equal_opportunity_score(y_ground, y_pred, A)\n",
    "    spd = utils.statistical_parity_score(y_ground, y_pred, A)\n",
    "    return {\n",
    "        \"acc\" : acc,\n",
    "        \"roc\" : roc,\n",
    "        \"eq_loss\" : eq_loss,\n",
    "        \"eod\" : eod,\n",
    "        \"spd\" : spd\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == \"XtremeFair\":\n",
    "        def model(**params):\n",
    "            return models.XtremeFair(**params)\n",
    "    elif model_name == \"XtremeFair_grad\":\n",
    "        def model(**params):\n",
    "            return models.XtremeFair(dual_learning=\"gradient\", **params)\n",
    "    elif model_name == \"XGBClassifier\":\n",
    "        def model(**params):\n",
    "            assert params[\"fair_weight\"] == 0\n",
    "            return models.XtremeFair(**params)\n",
    "    return model\n",
    "    \n",
    "def get_param_spaces(model_name):\n",
    "    if model_name == \"XtremeFair\":\n",
    "        return models.PARAM_SPACES[\"XtremeFair\"]\n",
    "    elif model_name == \"XtremeFair_grad\":\n",
    "        return models.PARAM_SPACES[\"XtremeFair\"]\n",
    "    elif model_name == \"XGBClassifier\":\n",
    "        return models.PARAM_SPACES[\"XGBClassifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgroup_experiment(args):\n",
    "    # create output directory if not exists\n",
    "    if not os.path.exists(args[\"output_dir\"]):\n",
    "        os.makedirs(args[\"output_dir\"])\n",
    "\n",
    "    results = []\n",
    "\n",
    "    cat_features = data.CAT_FEATURES[args[\"dataset\"]]\n",
    "    num_features = data.NUM_FEATURES[args[\"dataset\"]]\n",
    "    col_trans = ColumnTransformer(\n",
    "        [\n",
    "            (\"numeric\", StandardScaler(), num_features),\n",
    "            (\n",
    "                \"categorical\",\n",
    "                OneHotEncoder(\n",
    "                    drop=\"if_binary\", sparse_output=False, handle_unknown=\"ignore\"\n",
    "                ),\n",
    "                cat_features,\n",
    "            ),\n",
    "        ],\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "    col_trans.set_output(transform=\"pandas\")\n",
    "    scorer = utils.get_combined_metrics_scorer(\n",
    "        alpha=args[\"alpha\"], performance_metric=\"acc\", fairness_metric=\"eod\"\n",
    "    )\n",
    "\n",
    "    for i in tqdm(range(10)):\n",
    "        # Load and prepare data\n",
    "        X_train, Y_train, X_val, Y_val, X_test, Y_test = data.get_fold(\n",
    "            args[\"dataset\"], i, 0\n",
    "        )\n",
    "\n",
    "        # Define sensitive attribute from gender and age\n",
    "        A_train, A_val, A_test = get_subgroup_feature(\n",
    "            args[\"dataset\"], X_train, X_val, X_test\n",
    "        )\n",
    "\n",
    "        preprocess = Pipeline([(\"preprocess\", col_trans)])\n",
    "        preprocess.fit(X_train)\n",
    "        X_train = preprocess.transform(X_train)\n",
    "        X_val = preprocess.transform(X_val)\n",
    "        X_test = preprocess.transform(X_test)\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        objective = lambda trial: run_trial(\n",
    "            trial,\n",
    "            scorer,\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            A_train,\n",
    "            X_val,\n",
    "            Y_val,\n",
    "            A_val,\n",
    "            get_model(args[\"model_name\"]),\n",
    "            get_param_spaces(args[\"model_name\"]),\n",
    "            0,\n",
    "        )\n",
    "        study.optimize(objective, n_trials=args[\"n_trials\"])\n",
    "\n",
    "        # save best params\n",
    "        with open(os.path.join(args[\"output_dir\"], f\"best_params.txt\"), \"w+\") as f:\n",
    "            f.write(str(study.best_params))\n",
    "\n",
    "        model = models.XtremeFair(**study.best_params)\n",
    "        model.fit(X_train, Y_train, A_train)\n",
    "        y_prob = model.predict_proba(X_train)[:, 1]\n",
    "        thresh = utils.get_best_threshold(Y_train, y_prob)\n",
    "        y_prob_test = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred_test = y_prob_test > thresh\n",
    "\n",
    "        metrics = eval_model(Y_test, y_prob_test, y_pred_test, A_test)\n",
    "        results.append(metrics)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv(os.path.join(args[\"output_dir\"], \"results.csv\"))\n",
    "    results.mean().to_csv(os.path.join(args[\"output_dir\"], \"results_mean.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:38<00:16,  5.65s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10/10 [00:47<00:00,  4.79s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 1,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german/XtremeFair_1\",\n",
    "    \"model_name\" : \"XtremeFair\",\n",
    "    \"n_trials\" : 100\n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:24<00:11,  3.67s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10/10 [00:35<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 1,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german/XtremeFair_grad\",\n",
    "    \"model_name\" : \"XtremeFair_grad\",\n",
    "    \"n_trials\" : 100\n",
    "    \n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovani/hiaac/dual_fair_boost/notebooks/../scripts/utils.py:126: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(y_ground * np.log(y_prob) + (1 - y_ground) * np.log(1 - y_prob))\n",
      " 70%|███████   | 7/10 [00:18<00:08,  2.80s/it]/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/giovani/anaconda3/envs/dual_fair_boost/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"dataset\" : \"german2\",\n",
    "    \"alpha\" : 1,\n",
    "    \"output_dir\" : \"../results/subgroup_experiment/german/XGBClassifier\",\n",
    "    \"model_name\" : \"XGBClassifier\",\n",
    "    \"n_trials\" : 100\n",
    "}\n",
    "subgroup_experiment(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dual_fair_boost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
